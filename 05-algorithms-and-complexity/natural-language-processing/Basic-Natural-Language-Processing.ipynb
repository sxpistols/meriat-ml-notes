{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Natural Language Toolkit - Biblioteca para se trabalhar com linguagem natural \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary had a little lamb.', 'Her fleece was white as snow']\n"
     ]
    }
   ],
   "source": [
    "# Frase a ser analisada\n",
    "text = \"Mary had a little lamb. Her fleece was white as snow\"\n",
    "\n",
    "# Importamos as funcoes para extrair palavras e frases/sentencas\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "#nltk.download()\n",
    "\n",
    "# Executa a acao de extracao de sentenças no texto sugerido\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "# Exibe o resultado, que sera uma lista de frases/sentencas\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mary', 'had', 'a', 'little', 'lamb', '.'], ['Her', 'fleece', 'was', 'white', 'as', 'snow']]\n"
     ]
    }
   ],
   "source": [
    "# Percorremos a listagem de sentenças para a extração das palavras\n",
    "words=[word_tokenize(sent) for sent in sents]\n",
    "\n",
    "# O resultado será duas listas de palavras. Uma para cada sentença obtida.\n",
    "print(words)\n",
    "\n",
    "# Vale notar que as pontuações são tratadas como entidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords\n",
    "\n",
    "Hora de remover as palavras que não adicionam informação relevante ao contexto da sentença.\n",
    "\n",
    "Vamos começar utilizando a frase anterior para remover as stopwords. Em nosso cenário queremos remover coisas como a, and the period, and was, and as, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from string import punctuation\n",
    "\n",
    "# Um dos principais recursos que dispomos é uma coleção de stopwords em diferentes línguas.\n",
    "# Vamos utilizar esta coleção apontada para o idioma correto.\n",
    "# Não esquecer de importar também as pontuações, que são tratadas como entidades específicas.\n",
    "# Neste caso utilizamos uma lista de pontuações disponíveis no módulo python e combinamos com as stopwords.\n",
    "# Agora temos uma lista de palavras que queremos filtrar.\n",
    "# Note how we have stored all the stopwords in a set and not a list because the order really doesn't matter here. \n",
    "\n",
    "customStopWords = set(stopwords.words('english') + list(punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, dada qualquer lista de tokens ou palavras que você tem por tokenizing um pedaço de texto, você pode tomar isso e apenas filtrá-lo para apenas as palavras que não estão na lista de stopwords personalizado. Assim você começ uma lista das palavras que tem todas as palavras-chaves removidas.\n",
    "\n",
    "So you can see how from the sentence, Mary had a little lamb, the words had and a are removed now, and from her fleece was white as snow, we have removed the words was and as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', 'little', 'lamb', 'Her', 'fleece', 'white', 'snow']\n"
     ]
    }
   ],
   "source": [
    "wordsWOStopwords = [word for word in word_tokenize(text) if word not in customStopWords]\n",
    "\n",
    "print(wordsWOStopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocações são basicamente quaisquer palavras que são colocadas ou que ocorrem em conjunto. A partir do módulo de colocações, usamos uma classe chamada BigramCollocationFinder que ajuda a construir bigrams de uma determinada lista de palavras. \n",
    "\n",
    "Assim, usando a classe BigramCollocationFinder e usando o método from_words dessa classe, você pode construir bigrams e armazená-los em uma classe chamada finder. \n",
    "\n",
    "Agora, o objeto finder tem seu próprio método para realmente imprimir todos os bigrams que ele é construído. Dentro do objeto finder, temos todos os bigrams que estão presentes nesta lista de palavras e suas freqüências. \n",
    "\n",
    "Assim, cada bigram ocorre juntamente com o número de vezes que ocorreu dentro dessa lista de palavras. Para imprimi-los, usamos a função ngram_fd.items e ele irá imprimir todos os bigrams junto com suas freqüências. \n",
    "\n",
    "Se você tivesse um pedaço de texto em que os bigrams em particular fossem mais importantes do que outros, então esse pedaço particular de código classificaria todos os bigrams na ordem de sua freqüência e veria os bigrams mais importantes no topo. \n",
    "\n",
    "O módulo de colocações também tem um localizador de colocação de trigramas, que você pode usar de uma maneira muito semelhante para encontrar trigramas, ou grupos de palavras em três."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Her', 'fleece'), 1),\n",
       " (('Mary', 'little'), 1),\n",
       " (('fleece', 'white'), 1),\n",
       " (('lamb', 'Her'), 1),\n",
       " (('little', 'lamb'), 1),\n",
       " (('white', 'snow'), 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(wordsWOStopwords)\n",
    "\n",
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'clos', 'on', 'clos', 'night', 'when', 'she', 'was', 'in', 'the', 'mood', 'to', 'clos', '.']\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Mary closed on closing night when she was in the mood to close.\"\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st=LancasterStemmer()\n",
    "stemmedWords=[st.stem(word) for word in word_tokenize(text2)]\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mary', 'NNP'),\n",
       " ('closed', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('closing', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mood', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('close', 'VB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.01') the lowest part of the musical range\n",
      "Synset('bass.n.02') the lowest part in polyphonic music\n",
      "Synset('bass.n.03') an adult male singer with the lowest voice\n",
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n",
      "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n",
      "Synset('bass.n.06') the lowest adult male singing voice\n",
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n",
      "Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n",
      "Synset('bass.s.01') having or denoting a low vocal or instrumental range\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for ss in wn.synsets('bass'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "sense1 = lesk(word_tokenize(\"Sing in a lower tone, along with the bass\"),'bass')\n",
    "print(sense1, sense1.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"
     ]
    }
   ],
   "source": [
    "sense2 = lesk(word_tokenize(\"This sea bass was really hard to catch\"),'bass')\n",
    "print(sense2, sense2.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
