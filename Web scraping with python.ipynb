{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "\n",
    "What is web scraping? It's the process of extracting information from a web page by taking advantage of patterns in the web page's underlying code. Let's start looking for these patterns!\n",
    "\n",
    "### Fact 1: HTML consists of tags\n",
    "\n",
    "You can see that the HTML contains the article text, along with \"tags\" (specified using angle brackets) that \"mark up\" the text. (\"HTML\" stands for Hyper Text Markup Language.)\n",
    "\n",
    "For example, one tag is `<strong>`, which means \"use bold formatting\". There is a `<strong>` tag before \"Jan. 21\" and a </strong> tag after it. The first is an \"opening tag\" and the second is a \"closing tag\" (denoted by the /), which indicates to the web browser where to start and stop applying the formatting. In other words, this tag tells the web browser to make the text \"Jan. 21\" bold. (Don't worry about the &nbsp; - we'll deal with that later.)\n",
    "\n",
    "### Fact 2: Tags can have attributes\n",
    "\n",
    "HTML tags can have \"attributes\", which are specified in the opening tag. For example, `<span class=\"short-desc\">` indicates that this particular `<span>` tag has a class attribute with a value of short-desc.\n",
    "\n",
    "For the purpose of web scraping, you don't actually need to understand the meaning of `<span>`, class, or short-desc. Instead, you just need to recognize that tags can have attributes, and that they are specified in this particular way.\n",
    "\n",
    "### Fact 3: Tags can be nested\n",
    "\n",
    "Let's pretend my HTML code said:\n",
    "\n",
    "Hello `<strong><em>Data School</em> students</strong>`\n",
    "\n",
    "The text Data School students would be bold, because all of that text is between the opening `<strong>` tag and the closing `</strong>` tag. The text Data School would also be in italics, because the `<em>` tag means \"use italics\". The text \"Hello\" would not be bold or italics, because it's not within either the `<strong>` or `<em>` tags. Thus, it would appear as follows:\n",
    "\n",
    "Hello Data School students\n",
    "\n",
    "The central point to take away from this example is that tags \"mark up\" text from wherever they open to wherever they close, regardless of whether they are nested within other tags.\n",
    "\n",
    "Got it? You now know enough about HTML in order to start web scraping!\n",
    "\n",
    "### Reading the web page into Python\n",
    "\n",
    "The first thing we need to do is to read the HTML for this article into Python, which we'll do using the requests library. (If you don't have it, you can pip install requests from the command line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests  \n",
    "r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above fetches our web page from the URL, and stores the result in a \"response\" object called r. That response object has a text attribute, which contains the same HTML code we saw when viewing the source from our web browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if (gt IE 9)|!(IE)]> <!--><html lang=\"en\" class=\"no-js page-interactive section-opinion page-theme-standard tone-opinion page-interactive-default limit-small layout-xlarge app-interactive\" itemid=\"https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html\" itemtype=\"http://schema.org/NewsArticle\" itemscope xmlns:og=\"http://opengraphprotocol.org/schema/\"><!--<![endif]-->\n",
      "<!--[if IE 9]> <html lang=\"en\" class=\"no-js ie9 lt-ie10 page-interactive section-opinion page\n"
     ]
    }
   ],
   "source": [
    "# print the first 500 characters of the HTML\n",
    "print(r.text[0:500]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the HTML using Beautiful Soup\n",
    "\n",
    "We're going to parse the HTML using the Beautiful Soup 4 library, which is a popular Python library for web scraping. (If you don't have it, you can pip install beautifulsoup4 from the command line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "soup = BeautifulSoup(r.text, 'html.parser') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above parses the HTML (stored in r.text) into a special object called soup that the Beautiful Soup library understands. In other words, Beautiful Soup is reading the HTML and making sense of its structure.\n",
    "\n",
    "(Note that html.parser is the parser included with the Python standard library, though other parsers can be used by Beautiful Soup. See differences between parsers to learn more.)\n",
    "\n",
    "### Collecting all of the records\n",
    "\n",
    "The Python code above is the standard code I use with every web scraping project. Now, we're going to start taking advantage of the patterns we noticed in the article formatting to build our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = soup.find_all('span', attrs={'class':'short-desc'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code searches the soup object for all `<span>` tags with the attribute class=\"short-desc\". It returns a special Beautiful Soup object (called a \"ResultSet\") containing the search results.\n",
    "\n",
    "results acts like a Python list, so we can check its length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 116 results, which seems reasonable given the length of the article. (If this number did not seem reasonable, we would examine the HTML further to determine if our assumptions about the patterns in the HTML were incorrect.)\n",
    "\n",
    "We can also slice the object like a list, in order to examine the first three results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>,\n",
       " <span class=\"short-desc\"><strong>Jan. 21 </strong>“A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.” <span class=\"short-truth\"><a href=\"http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/\" target=\"_blank\">(Trump was on the cover 11 times and Nixon appeared 55 times.)</a></span></span>,\n",
       " <span class=\"short-desc\"><strong>Jan. 23 </strong>“Between 3 million and 5 million illegal votes caused me to lose the popular vote.” <span class=\"short-truth\"><a href=\"https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html\" target=\"_blank\">(There's no evidence of illegal voting.)</a></span></span>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also check that the last result in this object matches the last record in the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Nov. 11 </strong>“I'd rather have him  – you know, work with him on the Ukraine than standing and arguing about whether or not  – because that whole thing was set up by the Democrats.” <span class=\"short-truth\"><a href=\"https://www.nytimes.com/interactive/2017/12/10/us/politics/trump-and-russia.html\" target=\"_blank\">(There is no evidence that Democrats \"set up\" Russian interference in the election.)</a></span></span>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the date\n",
    "\n",
    "Web scraping is often an iterative process, in which you experiment with your code until it works exactly as you desire. To simplify the experimentation, we'll start by only working with the first record in the results object, and then later on we'll modify our code to use a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result = results[0]  \n",
    "first_result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although first_result may look like a Python string, you'll notice that there are no quote marks around it. Instead, it's another special Beautiful Soup object (called a \"Tag\") that has specific methods and attributes.\n",
    "\n",
    "In order to locate the date, we can use its find() method to find a single tag that matches a specific pattern, in contrast to the find_all() method we used above to find all tags that match a pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<strong>Jan. 21 </strong>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.find('strong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code searches first_result for the first instance of a `<strong>` tag, and again returns a Beautiful Soup \"Tag\" object (not a string).\n",
    "\n",
    "Since we want to extract the text between the opening and closing tags, we can access its text attribute, which does in fact return a regular Python string:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is \\xa0? You don't actually need to know this, but it's called an \"escape sequence\" that represents the &nbsp; character we saw earlier in the HTML source.\n",
    "\n",
    "However, you do need to know that an escape sequence represents a single character within a string. Let's slice it off from the end of the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan. 21'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.find('strong').text[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan. 21, 2017'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we're going to add the year, since we don't want our dataset to include ambiguous dates:\n",
    "first_result.find('strong').text[0:-1] + ', 2017'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the lie\n",
    "\n",
    "Let's take another look at first_result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to extract the two sentences about Iraq. Unfortunately, there isn't a pair of opening and closing tags that starts immediately before the lie and ends immediately after the lie. Therefore, we're going to have to use a different technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<strong>Jan. 21 </strong>,\n",
       " \"“I wasn't a fan of Iraq. I didn't want to go into Iraq.” \",\n",
       " <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first_result \"Tag\" has a contents attribute, which returns a Python list containing its \"children\". What are children? They are the Tags and strings that are nested within a Tag.\n",
    "\n",
    "We can slice this list to extract the second element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"“I wasn't a fan of Iraq. I didn't want to go into Iraq.” \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.contents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I wasn't a fan of Iraq. I didn't want to go into Iraq.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we'll slice off the curly quotation marks as well as the extra space at the end:\n",
    "first_result.contents[1][1:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the explanation\n",
    "\n",
    "Based upon what you've seen already, you might have figured out that we have at least two options for how we extract the third component of the record, which is the writer's explanation of why the President's statement was a lie.\n",
    "\n",
    "The first option is to slice the contents attribute, like we did when extracting the lie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.contents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second option is to search for the surrounding tag, like we did when extracting the date:\n",
    "first_result.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He was for an invasion before he was against it.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either way, we can access the text attribute and then slice off the opening and closing parentheses:\n",
    "first_result.find('a').text[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the URL\n",
    "Finally, we want to extract the URL of the article that substantiates the writer's claim that the President was lying.\n",
    "\n",
    "Let's examine the <a> tag within first_result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.find('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far in this tutorial, we have been extracting text that is between tags. In this case, the text we want to extract is located within the tag itself. Specifically, we want to access the value of the href attribute within the `<a>` tag.\n",
    "\n",
    "Beautiful Soup treats tag attributes and their values like key-value pairs in a dictionary: you put the attribute name in brackets (like a dictionary key), and you get back the attribute's value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.find('a')['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: Beautiful Soup methods and attributes\n",
    "\n",
    "Before we finish building the dataset, I want to summarize a few ways you can interact with Beautiful Soup objects.\n",
    "\n",
    "You can apply these two methods to either the initial soup object or a Tag object (such as first_result):\n",
    "\n",
    "* find(): searches for the first matching tag, and returns a Tag object\n",
    "* find_all(): searches for all matching tags, and returns a ResultSet object (which you can treat like a list of Tags)\n",
    "\n",
    "You can extract information from a Tag object (such as first_result) using these two attributes:\n",
    "\n",
    "* text: extracts the text of a Tag, and returns a string\n",
    "* contents: extracts the children of a Tag, and returns a list of Tags and strings\n",
    "\n",
    "It's important to keep track of whether you are interacting with a Tag, ResultSet, list, or string, because that affects which methods and attributes you can access.\n",
    "\n",
    "And of course, there are many more methods and attributes available to you, which are described in the Beautiful Soup documentation.\n",
    "\n",
    "### Building the dataset\n",
    "\n",
    "Now that we've figured out how to extract the four components of first_result, we can create a loop to repeat this process on all 116 results. We'll store the output in a list of tuples called records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = []  \n",
    "for result in results:  \n",
    "    date = result.find('strong').text[0:-1] + ', 2017'\n",
    "    lie = result.contents[1][1:-2]\n",
    "    explanation = result.find('a').text[1:-1]\n",
    "    url = result.find('a')['href']\n",
    "    records.append((date, lie, explanation, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since there were 116 results, we should have 116 records:\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jan. 21, 2017',\n",
       "  \"I wasn't a fan of Iraq. I didn't want to go into Iraq.\",\n",
       "  'He was for an invasion before he was against it.',\n",
       "  'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'),\n",
       " ('Jan. 21, 2017',\n",
       "  'A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.',\n",
       "  'Trump was on the cover 11 times and Nixon appeared 55 times.',\n",
       "  'http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/'),\n",
       " ('Jan. 23, 2017',\n",
       "  'Between 3 million and 5 million illegal votes caused me to lose the popular vote.',\n",
       "  \"There's no evidence of illegal voting.\",\n",
       "  'https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do a quick spot check of the first three records:\n",
    "records[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a tabular data structure\n",
    "\n",
    "The last major step in this process is to apply a tabular data structure to our existing structure (which is a list of tuples). We're going to do this using the pandas library, an incredibly popular Python library for data analysis and manipulation. (If you don't have it, here are the installation instructions.)\n",
    "\n",
    "The primary data structure in pandas is the \"DataFrame\", which is suitable for tabular data with columns of different types, similar to an Excel spreadsheet or SQL table. We can convert our list of tuples into a DataFrame by passing it to the DataFrame constructor and specifying the desired column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "df = pd.DataFrame(records, columns=['date', 'lie', 'explanation', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lie</th>\n",
       "      <th>explanation</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan. 21, 2017</td>\n",
       "      <td>I wasn't a fan of Iraq. I didn't want to go in...</td>\n",
       "      <td>He was for an invasion before he was against it.</td>\n",
       "      <td>https://www.buzzfeed.com/andrewkaczynski/in-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan. 21, 2017</td>\n",
       "      <td>A reporter for Time magazine — and I have been...</td>\n",
       "      <td>Trump was on the cover 11 times and Nixon appe...</td>\n",
       "      <td>http://nation.time.com/2013/11/06/10-things-yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan. 23, 2017</td>\n",
       "      <td>Between 3 million and 5 million illegal votes ...</td>\n",
       "      <td>There's no evidence of illegal voting.</td>\n",
       "      <td>https://www.nytimes.com/2017/01/23/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan. 25, 2017</td>\n",
       "      <td>Now, the audience was the biggest ever. But th...</td>\n",
       "      <td>Official aerial photos show Obama's 2009 inaug...</td>\n",
       "      <td>https://www.nytimes.com/2017/01/21/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan. 25, 2017</td>\n",
       "      <td>Take a look at the Pew reports (which show vot...</td>\n",
       "      <td>The report never mentioned voter fraud.</td>\n",
       "      <td>https://www.nytimes.com/2017/01/24/us/politics...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                                lie  \\\n",
       "0  Jan. 21, 2017  I wasn't a fan of Iraq. I didn't want to go in...   \n",
       "1  Jan. 21, 2017  A reporter for Time magazine — and I have been...   \n",
       "2  Jan. 23, 2017  Between 3 million and 5 million illegal votes ...   \n",
       "3  Jan. 25, 2017  Now, the audience was the biggest ever. But th...   \n",
       "4  Jan. 25, 2017  Take a look at the Pew reports (which show vot...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0   He was for an invasion before he was against it.   \n",
       "1  Trump was on the cover 11 times and Nixon appe...   \n",
       "2             There's no evidence of illegal voting.   \n",
       "3  Official aerial photos show Obama's 2009 inaug...   \n",
       "4            The report never mentioned voter fraud.   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.buzzfeed.com/andrewkaczynski/in-20...  \n",
       "1  http://nation.time.com/2013/11/06/10-things-yo...  \n",
       "2  https://www.nytimes.com/2017/01/23/us/politics...  \n",
       "3  https://www.nytimes.com/2017/01/21/us/politics...  \n",
       "4  https://www.nytimes.com/2017/01/24/us/politics...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
