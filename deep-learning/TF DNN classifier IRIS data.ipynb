{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from six.moves.urllib.request import urlopen\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  # If the training and test sets aren't stored locally, download them.\n",
    "  if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "      f.write(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load downloaded CSV files as TF data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TRAINING,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TEST,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a DNN classifer with some hidden units..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Temp\\tmpm2ljsmq0\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Temp\\\\tmpm2ljsmq0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000000288ACCC0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=[5,10,5],\n",
    "                                          n_classes=3,optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=0.01,\n",
    "                                                                                   l1_regularization_strength=0.0001),\n",
    "                                       activation_fn=tf.nn.sigmoid)\n",
    "                                          #model_dir=\"/tmp/iris_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(training_set.data)},\n",
    "      y=np.array(training_set.target),\n",
    "      num_epochs=None,\n",
    "      shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Temp\\tmpm2ljsmq0\\model.ckpt.\n",
      "INFO:tensorflow:loss = 144.229, step = 1\n",
      "INFO:tensorflow:global_step/sec: 909.039\n",
      "INFO:tensorflow:loss = 135.805, step = 101 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1123.53\n",
      "INFO:tensorflow:loss = 129.655, step = 201 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1052.57\n",
      "INFO:tensorflow:loss = 117.428, step = 301 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1086.89\n",
      "INFO:tensorflow:loss = 109.521, step = 401 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1111.05\n",
      "INFO:tensorflow:loss = 97.4582, step = 501 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1086.89\n",
      "INFO:tensorflow:loss = 86.9596, step = 601 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1041.61\n",
      "INFO:tensorflow:loss = 73.955, step = 701 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.21\n",
      "INFO:tensorflow:loss = 70.3577, step = 801 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1086.89\n",
      "INFO:tensorflow:loss = 73.8905, step = 901 (0.092 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Temp\\tmpm2ljsmq0\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 70.9648.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x2933e208>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model.\n",
    "classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define test input function and evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(test_set.data)},\n",
    "      y=np.array(test_set.target),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-11-08-00:53:29\n",
      "INFO:tensorflow:Restoring parameters from C:\\Temp\\tmpm2ljsmq0\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-08-00:53:29\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.533333, average_loss = 0.634277, global_step = 1000, loss = 19.0283\n",
      "\n",
      "Test Accuracy: 0.533333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Classify two new flower samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = np.array(\n",
    "      [[6.4, 5.2, 4.5, 1.5],\n",
    "       [5.8, 1.4, 5.0, 1.7]], dtype=np.float32)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": new_samples},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "predicted_classes = [p[\"classes\"] for p in predictions]\n",
    "predicted_classes = [int(str(x)[-3]) for x in predicted_classes]\n",
    "\n",
    "print(\"New Samples, Class Predictions:    {}\\n\"\n",
    "      .format(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
