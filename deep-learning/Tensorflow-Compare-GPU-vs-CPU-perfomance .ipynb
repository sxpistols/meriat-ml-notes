{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple performance compare Tensorflow using CPU and GPU for the some calculation\n",
    "\n",
    "It is well known that the GPU has huge speed performance in deep learning applications, but it would be nice to see on what scale.\n",
    "\n",
    "Before we get to the results, let's look at the reasons for the overperformance of the GPU compared to the CPU: Deep Learning involves a huge amount of matrix and vector operations, mostly multiplications that can be massively parallelized, which implies speed up on GPUs. This is because GPUs were designed to handle these matrix operations in parallel, as this is essential for computer games for e.g. 3D effects, land rendering, etc. On the other hand, a single core CPU would take a matrix operation in serial, one element at a time. A single GPU could have hundreds or thousands of cores, while a CPU typically has no more than a few cores (between two and eight).\n",
    "\n",
    "## Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "device_name = \"/gpu:1\"\n",
    "\n",
    "shape = (int(6500), int(6500))\n",
    "\n",
    "with tf.device(device_name):\n",
    "    random_matrix = tf.random_uniform(shape=shape, minval=0, maxval=1)\n",
    "    dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
    "    sum_operation = tf.reduce_sum(dot_operation)\n",
    "\n",
    "\n",
    "startTime = datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "        result = session.run(sum_operation)\n",
    "        \n",
    "        \n",
    "print(\"Shape:\", shape, \"Device:\", device_name)\n",
    "print(\"Time taken:\", datetime.now() - startTime)\n",
    "\n",
    "print(\"\\n\" * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6500, 6500) Device: /cpu:0\n",
      "Time taken: 0:00:22.878224\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device_name = \"/cpu:0\"\n",
    "\n",
    "shape = (int(6500), int(6500))\n",
    "\n",
    "with tf.device(device_name):\n",
    "    random_matrix = tf.random_uniform(shape=shape, minval=0, maxval=1)\n",
    "    dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
    "    sum_operation = tf.reduce_sum(dot_operation)\n",
    "\n",
    "\n",
    "startTime = datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "        result = session.run(sum_operation)\n",
    "\n",
    "        \n",
    "print(\"Shape:\", shape, \"Device:\", device_name)\n",
    "print(\"Time taken:\", datetime.now() - startTime)\n",
    "\n",
    "print(\"\\n\" * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://docs.devicehive.com/v2.0/blog/using-gpus-for-training-tensorflow-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "def get_times(maximum_time):\n",
    "\n",
    "    device_times = {\n",
    "        \"/gpu:1\":[],\n",
    "        \"/cpu:0\":[]\n",
    "    }\n",
    "    matrix_sizes = range(500,50000,50)\n",
    "\n",
    "    for size in matrix_sizes:\n",
    "        for device_name in device_times.keys():\n",
    "\n",
    "            print(\"####### Calculating on the \" + device_name + \" #######\")\n",
    "\n",
    "            shape = (size,size)\n",
    "            data_type = tf.float16\n",
    "            with tf.device(device_name):\n",
    "                r1 = tf.random_uniform(shape=shape, minval=0, maxval=1, dtype=data_type)\n",
    "                r2 = tf.random_uniform(shape=shape, minval=0, maxval=1, dtype=data_type)\n",
    "                dot_operation = tf.matmul(r2, r1)\n",
    "\n",
    "\n",
    "            with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "                    start_time = time.time()\n",
    "                    result = session.run(dot_operation)\n",
    "                    time_taken = time.time() - start_time\n",
    "                    print(result)\n",
    "                    device_times[device_name].append(time_taken)\n",
    "\n",
    "            print(device_times)\n",
    "\n",
    "            if time_taken > maximum_time:\n",
    "                return device_times, matrix_sizes\n",
    "\n",
    "\n",
    "device_times, matrix_sizes = get_times(1.5)\n",
    "gpu_times = device_times[\"/gpu:1\"]\n",
    "cpu_times = device_times[\"/cpu:0\"]\n",
    "\n",
    "plt.plot(matrix_sizes[:len(gpu_times)], gpu_times, 'o-')\n",
    "plt.plot(matrix_sizes[:len(cpu_times)], cpu_times, 'o-')\n",
    "plt.ylabel('Time')\n",
    "plt.xlabel('Matrix size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
