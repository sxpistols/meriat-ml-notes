{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que é uma Rede Neural Artificial?\n",
    "\n",
    "Uma rede neural artificial é um grafo composto por funções matemáticas como combinações lineares e funções de ativação. O grafo consiste de nós e arestas.\n",
    "\n",
    "Nós em cada camada (exceto por nós na camada de entrada), realizam funções matemáticas usando como entrada a saída das camadas anteriores. Por exemplo, um nó pode representar `f(x,y)=x+y`, onde `x` e `y` são valores de entrada vindos da camada anterior.\n",
    "\n",
    "De forma similar, cada nó cria uma saída que pode ser passada para os nós da próxima camada. O valor de saída da camada de saída não é passada para uma camada futura (pois é a última!).\n",
    "\n",
    "Camadas entre a camada de entrada e a de saída são chamadas de camadas ocultas.\n",
    "\n",
    "## Propagação para a Frente\n",
    "\n",
    "Ao propagar valores da primeira cada (camada de entrada) através das funções matemáticas apresentadas em cada nó, a rede emite um valor de saída. Este processo é chamado de propagação para a frente, ou forward pass.\n",
    "\n",
    "Aqui está um exemplo simples de propagação para a frente.\n",
    "\n",
    "## Grafos\n",
    "\n",
    "Os nós e arestas criam uma estrutura de grafo. Apesar de que o exemplo acima é razoavelmente simples, não é difícil imaginar que grafos crescentemente complexos sejam capazes de calcular... bem... qualquer qualquer coisa.\n",
    "\n",
    "Existem geralmente dois passos para a criação de uma rede neural:\n",
    "\n",
    "1. Definir o grafo de nós e arestas.\n",
    "2. Propagar os valores dentro do grafo.\n",
    "\n",
    "O `NanoFlow` trabalha da mesma forma. Você definirá os nós e arestas da sua rede com um método e irá propagar os valores dentro do grafo usando outro método. \n",
    "\n",
    "Sabemos que cada nó pode receber entradas de diversos outros nós. Sabemos também que cada nó cria uma saída única, que muito provavelmente será passada para outros nós. Vamos adicionar duas listas então: uma para adicionar referências aos nós de entrada, e outra para as referências dos nós de saída.\n",
    "\n",
    "Sabemos que cada nó pode receber entradas de diversos outros nós. Sabemos também que cada nó cria uma saída única, que muito provavelmente será passada para outros nós. Vamos adicionar duas listas então: uma para adicionar referências aos nós de entrada, e outra para as referências dos nós de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, inbound_nodes=[]):\n",
    "        # Nó(s) que fornecem valores para o nó corrente. Referência aos nós de entrada.\n",
    "        self.inbound_nodes = inbound_nodes\n",
    "        # Nó(s) aos quais o nó corrente passa valores. Referência aos nós de saída.\n",
    "        self.outbound_nodes = []\n",
    "        # Para cada nó  aqui, adicionamos este nó como um nó de saída *daquele* nó.\n",
    "        for n in self.inbound_nodes:\n",
    "            n.outbound_nodes.append(self)\n",
    "        # Cada nó eventualmente calculará um valor que representa a sua saída\n",
    "        self.value = None\n",
    "        \n",
    "    # Cada nó será capaz de passar valores \"forward propagation\" e \"back propagation\".\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Propagação para a frente.\n",
    "\n",
    "        Calcula o valor de saída baseando-se nos `inbound_nodes` e\n",
    "        armazena o valor final em self.value.\n",
    "        \"\"\"\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A subclasse Node\n",
    "Diferentemente das outras subclasses de `Node`, a subclasse `Input` não calcula nada. A subclasse `Input` apenas armazena um valor `value`, como um dado de um atributo ou um parâmetro do modelo (peso/viés).\n",
    "\n",
    "Você pode definir o valor `value` de forma explícita ou usando o método `forward()`. Este valor é usado para alimentar o restante da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        # Um nó Input não possui nós de entrada,\n",
    "        # então não há necessidade de passar nada para o construtor.\n",
    "        Node.__init__(self)\n",
    "\n",
    "    # NOTA: O nó Input é o único onde o valor pode\n",
    "    # ser passado como um argumento para forward().\n",
    "    #\n",
    "    # Todas as outras implementações de nós devem receber o valor\n",
    "    # do nó anterior disponível em self.inbound_nodes\n",
    "    #\n",
    "    # Exemplo:\n",
    "    # val0 = self.inbound_nodes[0].value\n",
    "    def forward(self, value=None):\n",
    "        # Sobre-escreva o valor se um valor foi fornecido.\n",
    "        if value is not None:\n",
    "            self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A subclasse Add\n",
    "\n",
    "Note a diferença no método `__init__: Add.__init__(self, [x, y])`. Diferentemente da classe `Input`, que não possui nós como entrada, a subclasse `Add` recebe dois nós no momento de sua criação, x e y, e adiciona os valores destes nós.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can you augment the Add class so that it accepts any number of nodes as input?\n",
    "\n",
    "Hint: this may be useful:\n",
    "https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists\n",
    "\"\"\"\n",
    "class Add(Node):\n",
    "    # Utilizo o construtor para passar os \"inbound_nodes\" isnanciados na classe Node\n",
    "    def __init__(self, x, y):\n",
    "        Node.__init__(self, [x, y])\n",
    " \n",
    "    def forward(self):\n",
    "        x_value = self.inbound_nodes[0].value\n",
    "        y_value = self.inbound_nodes[1].value\n",
    "        self.value = x_value + y_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NanoFlow possui dois métodos para te ajudar a definir e então executar valores dentro de seus grafos: **topological_sort()** e **forward_pass()**.\n",
    "\n",
    "### topological_sort\n",
    "\n",
    "Para definir a sua rede, você precisará definir a ordem das operações para os seus nós. Dado que a entrada de alguns nós depende da saída de outros nós, você precisará encadear o grafo de forma que as dependências das entradas de cada um dos nós estejam disponíveis antes de executar o seu cálculo. Esta técnica é chamada de [ordenação topológica](https://en.wikipedia.org/wiki/Topological_sorting).\n",
    "\n",
    "A função `topological_sort()` implementa a ordenação topológica usando o [Algoritmo de Kahn](https://en.wikipedia.org/wiki/Topological_sorting#Kahn.27s_algorithm). Os detalhes deste método não são importantes neste momento, mas seu resultado é, `topological_sort()` retorna uma lista de nós em uma sequência que permite que todos os cálculos sejam realizados de forma serializada (em série). O método `topological_sort()` recebe como entrada um `feed_dict`, que é como nós inicializamos um valor para um nó `Input`. O `feed_dict` é representado na forma de um dicionário Python. **Aqui está um exemplo de uso:**\n",
    "\n",
    "```python\n",
    "# Define 2 nós do tipo \"Input\".\n",
    "x, y = Input(), Input()\n",
    "# Define um nó do tipo \"Add\" e usa os dois nós do tipo \"Input\" como entrada.\n",
    "add = Add(x, y)\n",
    "# Os valores de \"x\" e \"y\" serão definidos como 10 e 20, respectivamente.\n",
    "feed_dict = {x: 10, y: 20}\n",
    "# Ordena os nós usando ordenação topológica.\n",
    "sorted_nodes = topological_sort(feed_dict=feed_dict)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the nodes in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Node and the value is the respective value feed to that Node.\n",
    "\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_nodes:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_nodes:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward_pass\n",
    "\n",
    "O outro método disponível é o **forward_pass()**, que de fato executa a rede e emite uma saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_pass(output_node, sorted_nodes):   \n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted nodes.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_node`: A node in the graph, should be the output node (have no outgoing edges). O nó de saída do grafo (sem arestas de saída).\n",
    "        `sorted_nodes`: A topologically sorted list of nodes. Uma lista topologicamente ordenada de nós.\n",
    "\n",
    "    Returns the output Node's value\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_nodes:\n",
    "        n.forward()\n",
    "\n",
    "    return output_node.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A subclasse Linear\n",
    "\n",
    "As redes neurais recebem entradas e produzem saídas. Redes neurais podem melhorar a acurácia de sua saída com o tempo.\n",
    "\n",
    "Um neurônio artificial simples depende de três componentes:\n",
    "\n",
    "* entradas, xi\n",
    "* pesos, wi\n",
    "* viés, b\n",
    "\n",
    "A saída, y, é a soma ponderada das entradas mais o viés.\n",
    "\n",
    "Ao variar os pesos, você pode variar a influência que qualquer entrada tenha na saída. O aspecto de aprendizagem de redes neurais se dá durante um processo chamado retro-propagação (backpropagation). Na retro-propagação, a rede modifica os pesos para melhorar a acurácia da saída da rede. Você irá aplicar estes conceitos em breve.\n",
    "\n",
    "A função Linear é um neurônio linear que gera uma saída ao aplicar uma versão simplificada de uma soma ponderada. A função Linear deve receber como entrada **n** nós de entrada, uma lista de pesos também com tamanho **n** e um viés (bias).\n",
    "\n",
    "Álgebra linear reflete bem a idéia de transformar valores em camadas em um grafo. Existe uma técnica chamada **transformation** que realiza exatamente o que uma **camada** deve fazer - ela converte entradas em saídas em diversas dimensões. Observe a equação de saída:\n",
    "\n",
    "![1](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5892a66c_neuron-output/neuron-output.png)\n",
    "\n",
    "Durante os cáculos, vamos denotar **x** como **X** e **w** como **W** pois estes são agora matrizes. Neste cenário **b** será um vetor ao invés de um valor escalar.\n",
    "\n",
    "Considere o nó **Linear** com uma entrada e **k** saídas (mapeando 1 entrada para k saídas). Neste contexto, uma entrada ou saída são sinônimos de atributos. Neste caso, **X** é uma matriz de 1 por 1.\n",
    "\n",
    "![1](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581f9571_newx/newx.png)\n",
    "\n",
    "**W** se torna uma matriz de ordem 1 por **k** (se parece como uma linha).\n",
    "\n",
    "![1](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581f9571_neww/neww.png)\n",
    "\n",
    "O resultado da multiplicação das matrizes **X** e **W** é uma matriz de ordem 1 por **k**. Como **b** também é uma matriz de 1 por **k**, **b** é adicionado diretamente a saída da multiplicação de **X** e **W**. E se quiséssemos mapear **n** entradas para **k** saídas?\n",
    "\n",
    "Então **X** seria uma matriz de 1 por **n** e **W** uma matriz de **n** por **k**. O resultado desta multiplicação ainda seria uma matriz de 1 por **k**, então o uso dos viéses continuam os mesmos.\n",
    "\n",
    "![1](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581f9570_newx-1n/newx-1n.png)\n",
    "![1](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a24e51_neww-nk-fixed/neww-nk-fixed.gif)\n",
    "![1](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581a94e5_b-1byk/b-1byk.png)\n",
    "\n",
    "Vamos ver agora um exemplo com **n** entradas. Considere uma imagem em escala de cinza de tamanho **28px** por **28px** (como o dataset MNIST). Nós podemos reformatar esta imagem para que ela se torne uma matriz de ordem **1 por 784**, ou seja, **n = 784**. Cada pixel é uma entrada/atributo.\n",
    "\n",
    "Na prática, o padrão é usar várias entradas simultaneas durante a \"passagem para a frente\" de uma rede neural. Não é factível usar uma entrada por vez. O principal motivo para isto é que cada um dos exemplos pode ser processado em paralelo, resultando em grandes melhorias em performance. O número de entradas é chamado de **batch size**. Números comuns para este parâmetro são 32, 64, 128, 256 e 512. Normalmente, estes são os máximos que conseguimos comportar em memória. O que isso significa para **X**, **W** e **b**?\n",
    "\n",
    "**X** se torna uma matriz de **m** por **n** enquanto **W** e **b** se mantém iguais. O resultado da multiplicação de matrizes é agora **m** por **k**, então a adioção de **b** é o resultado de um broadcast sobre cada linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    #def __init__(self, inputs, weights, bias):\n",
    "    def __init__(self, X, W, b):\n",
    "        #Node.__init__(self, [inputs, weights, bias])\n",
    "        Node.__init__(self, [X, W, b])\n",
    "\n",
    "        # NOTE: The weights and bias properties here are not\n",
    "        # numbers, but rather references to other nodes.\n",
    "        # The weight and bias values are stored within the\n",
    "        # respective nodes.\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Set self.value to the value of the linear function output. y=∑wi xi + b\n",
    "        \n",
    "        Nesta solução, eu defini self.value como sendo o viés (bias) e então iterei sobre os valores de entrada \n",
    "        e pesos, adicionando cada entrada já ponderada em self.value. Note que chamar .value em self.inbound_nodes[0] \n",
    "        ou self.inbound_nodes[1] nos retorna uma lista.\n",
    "        \"\"\"\n",
    "        #inputs = self.inbound_nodes[0].value\n",
    "        #weights = self.inbound_nodes[1].value\n",
    "        #bias = self.inbound_nodes[2]\n",
    "        #self.value = bias.value\n",
    "        #for x, w in zip(inputs, weights):\n",
    "        #    self.value += x * w\n",
    "            \n",
    "        \"\"\"\n",
    "        Na solução v2, estou preparando o NanoFlow para trabalhar com matrizes e vetores.\n",
    "        Você precisará usar o método np.dot, que trabalha como uma multiplicação de matrizes 2D, para multiplicar as matrizes de entrada e pesos da Equação (2).\n",
    "        É importante também notar que o numpy, na prática, sobrecarrega o operador __add__ para que você possa usá-lo diretamente com estruturas do tipo np.array (eg. np.array() + np.array()).\n",
    "        Obtive os valores de X, W e b das suas respectivas entradas. Eu usei o método np.dot para realizar a multiplicação de matrizes.\n",
    "        \"\"\"\n",
    "        X = self.inbound_nodes[0].value\n",
    "        W = self.inbound_nodes[1].value\n",
    "        b = self.inbound_nodes[2].value\n",
    "        self.value = np.dot(X, W) + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sigmoid\n",
    "\n",
    "Como você deve lembrar, redes neurais melhoram a acurácia de suas saídas ao modificar os pesos e viéses das suas saídas em resposta ao dados rotulados de treinamento.\n",
    "\n",
    "Existem diferentes técnicas para definir a acurácia de uma rede neural, sendo que todas estão focadas na habilidade das redes em aproximar as suas saídas às saídas esperadas. Diferentes métricas são usadas para medir a acurácia, normalmente sendo denominadas como **perda (loss)** ou **custo (cost)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Este método está isolado da função \"forward\" pois será usada na função \"backward\" também.\n",
    "\n",
    "        \"x\": Um objeto em formato de array numpy.\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-x)) # o `.` garante que `1` é um float\n",
    "\n",
    "    def forward(self):\n",
    "        input_value = self.inbound_nodes[0].value\n",
    "        self.value = self._sigmoid(input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.  4.]\n",
      " [-9.  4.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X, W, b = Input(), Input(), Input()\n",
    "\n",
    "f = Linear(X, W, b)\n",
    "\n",
    "X_ = np.array([[-1., -2.], [-1, -2]])\n",
    "W_ = np.array([[2., -3], [2., -3]])\n",
    "b_ = np.array([-3., -5])\n",
    "\n",
    "feed_dict = {X: X_, W: W_, b: b_}\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "output = forward_pass(f, graph)\n",
    "\n",
    "\"\"\"\n",
    "Output should be:\n",
    "[[-9., 4.],\n",
    "[-9., 4.]]\n",
    "\"\"\"\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
