{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple performance compare Tensorflow using CPU and GPU for the some calculation\n",
    "\n",
    "It is well known that the GPU has huge speed performance in deep learning applications, but it would be nice to see on what scale.\n",
    "\n",
    "Before we get to the results, let's look at the reasons for the overperformance of the GPU compared to the CPU: Deep Learning involves a huge amount of matrix and vector operations, mostly multiplications that can be massively parallelized, which implies speed up on GPUs. This is because GPUs were designed to handle these matrix operations in parallel, as this is essential for computer games for e.g. 3D effects, land rendering, etc. On the other hand, a single core CPU would take a matrix operation in serial, one element at a time. A single GPU could have hundreds or thousands of cores, while a CPU typically has no more than a few cores (between two and eight).\n",
    "\n",
    "## Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6500, 6500) Device: /gpu:1\n",
      "Time taken: 0:00:02.863188\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "device_name = \"/gpu:1\"\n",
    "\n",
    "shape = (int(6500), int(6500))\n",
    "\n",
    "with tf.device(device_name):\n",
    "    random_matrix = tf.random_uniform(shape=shape, minval=0, maxval=1)\n",
    "    dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
    "    sum_operation = tf.reduce_sum(dot_operation)\n",
    "\n",
    "\n",
    "startTime = datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "        result = session.run(sum_operation)\n",
    "        \n",
    "        \n",
    "print(\"Shape:\", shape, \"Device:\", device_name)\n",
    "print(\"Time taken:\", datetime.now() - startTime)\n",
    "\n",
    "print(\"\\n\" * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6500, 6500) Device: /cpu:0\n",
      "Time taken: 0:00:22.878224\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device_name = \"/cpu:0\"\n",
    "\n",
    "shape = (int(6500), int(6500))\n",
    "\n",
    "with tf.device(device_name):\n",
    "    random_matrix = tf.random_uniform(shape=shape, minval=0, maxval=1)\n",
    "    dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
    "    sum_operation = tf.reduce_sum(dot_operation)\n",
    "\n",
    "\n",
    "startTime = datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as session:\n",
    "        result = session.run(sum_operation)\n",
    "\n",
    "        \n",
    "print(\"Shape:\", shape, \"Device:\", device_name)\n",
    "print(\"Time taken:\", datetime.now() - startTime)\n",
    "\n",
    "print(\"\\n\" * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
